{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.5.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python35264bitf8c6bb909d074297b47234dde81826f2",
   "display_name": "Python 3.5.2 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "# load_data\n",
    "# split train data & test data\n",
    "# data normalization\n",
    "# define class\n",
    "# define criterion & loss\n",
    "# define train loop & validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    (0.5,), (0.5,)\n",
    "                                )])\n",
    "# Download and load the training & test data\n",
    "trainset = datasets.MNIST('../data/MNIST_data/', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('../data/MNIST_data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "# testset에도 batch를 사용해야 하는가? => ok\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data using iterator\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        ...,\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]]])"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784,512)\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.fc3 = nn.Linear(512,10)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch: 1 \tTraining Loss: -0.098933\nEpoch: 2 \tTraining Loss: -0.098714\nEpoch: 3 \tTraining Loss: -0.098747\nEpoch: 4 \tTraining Loss: -0.098747\nEpoch: 5 \tTraining Loss: -0.098764\nEpoch: 6 \tTraining Loss: -0.098697\nEpoch: 7 \tTraining Loss: -0.098714\nEpoch: 8 \tTraining Loss: -0.098714\nEpoch: 9 \tTraining Loss: -0.098697\nEpoch: 10 \tTraining Loss: -0.098714\nEpoch: 11 \tTraining Loss: -0.098714\nEpoch: 12 \tTraining Loss: -0.098714\nEpoch: 13 \tTraining Loss: -0.098697\nEpoch: 14 \tTraining Loss: -0.098714\nEpoch: 15 \tTraining Loss: -0.098731\nEpoch: 16 \tTraining Loss: -0.098731\nEpoch: 17 \tTraining Loss: -0.098781\nEpoch: 18 \tTraining Loss: -0.098731\nEpoch: 19 \tTraining Loss: -0.098731\nEpoch: 20 \tTraining Loss: -0.098731\n"
    }
   ],
   "source": [
    "epochs = 20\n",
    "steps = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "\n",
    "    for image, label in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        log_prob = model(image)\n",
    "        log_loss = criterion(log_prob, label)\n",
    "        log_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += log_loss.item()\n",
    "    train_loss = train_loss/len(trainloader)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 16 is out of bounds for dimension 0 with size 16",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0d7e038dcdeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# calculate test accuracy for each object class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mclass_correct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mclass_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 16 is out of bounds for dimension 0 with size 16"
     ]
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval() # prep model for *evaluation*\n",
    "\n",
    "for data, target in testloader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(BATCH_SIZE):\n",
    "        label = target[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(testloader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}